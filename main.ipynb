{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import VGG16\n",
    "\n",
    "size = (224, 224, 3)\n",
    "\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=size)\n",
    "\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 InputLayer False\n",
      "1 Conv2D False\n",
      "2 Conv2D False\n",
      "3 MaxPooling2D False\n",
      "4 Conv2D False\n",
      "5 Conv2D False\n",
      "6 MaxPooling2D False\n",
      "7 Conv2D False\n",
      "8 Conv2D False\n",
      "9 Conv2D False\n",
      "10 MaxPooling2D False\n",
      "11 Conv2D False\n",
      "12 Conv2D False\n",
      "13 Conv2D False\n",
      "14 MaxPooling2D False\n",
      "15 Conv2D False\n",
      "16 Conv2D False\n",
      "17 Conv2D False\n",
      "18 MaxPooling2D False\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(vgg16.layers):\n",
    "    print(str(i)+\" \"+layer.__class__.__name__, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 21,137,986\n",
      "Trainable params: 6,423,298\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "num_classes =2\n",
    "\n",
    "l = vgg16.output\n",
    "l = Flatten(name='flatten')(l)\n",
    "fc1 = Dense(256, activation='relu')(l)\n",
    "fc1 = Dropout(0.3)(fc1)\n",
    "fc_head = Dense(num_classes, activation='softmax')(fc1)\n",
    "\n",
    "model = Model(inputs = vgg16.input, outputs=fc_head)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_dir = './train'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  rotation_range=20,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   batch_size=6,\n",
    "                                                   class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "n_train = 50\n",
    "# n_validation = 246\n",
    "epochs = 15\n",
    "batch_size = 6\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "               optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "hostory = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=n_train//batch_size,\n",
    "                              epochs=epochs)\n",
    "#                              callbacks = callbacks,\n",
    "#                              validation_data = validation_generator,\n",
    "#                              validation_steps = n_validation//batch_size)\n",
    "\n",
    "model.save('save.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rice blast! 1\n",
      "Rice blast! 2\n",
      "Rice blast! 3\n",
      "Rice blast! 4\n",
      "Rice blast! 5\n",
      "Rice blast! 6\n",
      "Healthy\n",
      "Rice blast! 8\n",
      "Rice blast! 9\n",
      "Rice blast! 10\n",
      "Rice blast! 11\n",
      "Rice blast! 12\n",
      "Rice blast! 13\n",
      "Rice blast! 14\n",
      "Rice blast! 15\n",
      "Rice blast! 16\n",
      "Healthy\n",
      "Rice blast! 18\n",
      "Rice blast! 19\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "e1=0\n",
    "e2=0\n",
    "for i in range(1, 20):\n",
    "    pred = image.load_img('./test/'+str(i)+'.jpg', target_size=(224, 224))\n",
    "    img = cv2.imread('./test/'+str(i)+'.jpg')\n",
    "    pred = image.img_to_array(pred)\n",
    "    pred = np.expand_dims(pred, axis=0)\n",
    "\n",
    "    result = model.predict(pred)\n",
    "    if np.argmax(result[0]==0):\n",
    "        print(\"Healthy\")\n",
    "        cv2.imshow(\"Healthy\", img)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "        e1+=1\n",
    "    else:\n",
    "        print(\"Rice blast!\", i)\n",
    "        cv2.imshow(\"Rice blast\", img)\n",
    "        cv2.waitKey()\n",
    "        cv2.destroyAllWindows()\n",
    "        e2+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
